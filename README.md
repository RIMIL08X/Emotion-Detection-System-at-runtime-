# Real-Time Facial Emotion Recognition ğŸ˜„

A real-time **Facial Emotion Recognition (FER)** system built using **YOLOv8** for face detection, **OpenCV** for video capture, and a **custom CNN (`.h5`) model** trained on FER datasets for emotion classification.

---

## ğŸš€ Features

* Real-time emotion detection from webcam or video feed.
* Uses **YOLOv8** for accurate and fast face detection.
* Loads a **custom-trained CNN (.h5)** model for emotion classification.
* Bounding boxes with emotion labels drawn using OpenCV.
* Works on **CPU** or **GPU**.

---

## ğŸ§  Model Overview

### 1. **YOLOv8 (Face Detection)**

* Detects faces in real-time.
* Model file: `yolov8n-face.pt`
* Source: [YOLOv8n-Face Weights (Hugging Face)](https://huggingface.co/arnabdhar/YOLOv8n-face/resolve/main/yolov8n-face.pt)

### 2. **FER Model (Emotion Classification)**

* Trained **CNN** stored as `fer2013_cnn_model.h5`.
* Accepts cropped face images and classifies into:
  `['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']`

---

## âš™ï¸ Setup Instructions

Follow these steps to set up and run the project locally.

### 1ï¸âƒ£ Install `pyenv` and Python 3.11+

If you donâ€™t have Python 3.11 installed:

```bash
# Install pyenv (Ubuntu/Debian example)
curl https://pyenv.run | bash

# Add pyenv to PATH (add these lines to ~/.bashrc or ~/.zshrc)
export PATH="$HOME/.pyenv/bin:$PATH"
eval "$(pyenv init --path)"
eval "$(pyenv virtualenv-init -)"
```

Now install Python 3.11:

```bash
pyenv install 3.11.6
pyenv local 3.11.6
```

---

### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv emodetect-venv
source emodetect-venv/bin/activate
```

Or (if you prefer pyenvâ€™s virtualenv):

```bash
pyenv virtualenv 3.11.6 emodetect-venv
pyenv activate emodetect-venv
```

---

### 3ï¸âƒ£ Install Dependencies

All dependencies are listed in `requirements.txt`.

```bash
pip install -r requirements.txt
```

If you need GPU acceleration:

```bash
pip install tensorflow[and-cuda]
```

---

### 4ï¸âƒ£ Run the Real-Time Detector

Once setup is complete, start the live detection:

```bash
python live.py
```

**What happens:**

* YOLOv8 detects faces in the webcam feed.
* Each detected face is cropped and fed into the CNN.
* The CNN predicts the emotion label.
* Bounding boxes with emotion names are drawn live on the frame.

Press **`q`** to quit.

---

## ğŸ“ Project Structure

```
EMODetect/
â”‚
â”œâ”€â”€ __pycache__/                # Cached Python files
â”œâ”€â”€ model/                      # Directory containing trained model files
â”‚   â””â”€â”€ fer2013_cnn_model.h5    # CNN model trained on FER2013 dataset
â”‚
â”œâ”€â”€ live.py                     # Real-time detection (YOLO + CNN + OpenCV)
â”œâ”€â”€ preprocessing.py             # Dataset preprocessing utilities
â”œâ”€â”€ train.py                    # CNN training script
â”œâ”€â”€ yolov8n-face.pt             # YOLOv8 lightweight face detection model
â”œâ”€â”€ requirements.txt             # List of dependencies
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“Š Model Training Results

The CNN model was trained on the **FER2013 dataset**. Below are **two terminal snapshots** showing the training process, accuracy, and loss progression across epochs:

<p align="center">
  <img src="https://raw.githubusercontent.com/stormrimil/EMODetect/main/assets/training_terminal_1.png" alt="Training Log 1" width="600">
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/stormrimil/EMODetect/main/assets/training_terminal_2.png" alt="Training Log 2" width="600">
</p>

> *(Ensure both screenshots are uploaded to your GitHub repo at `assets/` path for direct rendering.)*

Example performance: **~85% validation accuracy** after fine-tuning.

---

## ğŸ¥ Example Live Output

When you run `live.py`, youâ€™ll see real-time bounding boxes and labels like:

```
[Happy]  ğŸ˜Š
[Angry]  ğŸ˜ 
[Neutral] ğŸ˜
```

---

## ğŸ§© Troubleshooting

| Issue                                          | Solution                                                          |
| ---------------------------------------------- | ----------------------------------------------------------------- |
| `FileNotFoundError: yolov8n-face.pt not found` | Download the YOLOv8n-Face model and place it in the project root. |
| TensorRT / CUDA warnings                       | Ignore if not using GPU acceleration.                             |
| Webcam not opening                             | Change `cv2.VideoCapture(0)` to another index (like `1` or `2`).  |

---

## ğŸ“š References

* [Ultralytics YOLOv8 Docs](https://docs.ultralytics.com)
* [FER2013 Dataset (Kaggle)](https://www.kaggle.com/datasets/msambare/fer2013)
* [OpenCV Official Documentation](https://docs.opencv.org)

---

## ğŸ‘¨â€ğŸ’» Author

**Storm (Rimil)**
CSE Student @ SRM Kattankulathur
Focus: Computer Vision | Deep Learning | Reinforcement Learning

---

## ğŸ§¾ License

This project is licensed under the **MIT License** â€“ free to use and modify for research and educational purposes.

---

### âœ… Quick Summary

| Step                   | Command                                                               |
| ---------------------- | --------------------------------------------------------------------- |
| Setup Python via pyenv | `pyenv install 3.11.6`                                                |
| Create & activate venv | `python -m venv emodetect-venv && source emodetect-venv/bin/activate` |
| Install dependencies   | `pip install -r requirements.txt`                                     |
| Run the project        | `python live.py`                                                      |
